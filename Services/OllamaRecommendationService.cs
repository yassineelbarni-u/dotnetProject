using System.Text;
using System.Text.Json;
using ProjetTestDotNet.Data;
using Microsoft.EntityFrameworkCore;

namespace ProjetTestDotNet.Services
{
    /// <summary>
    /// Service de recommandation utilisant Ollama (LLM local) avec architecture RAG.
    /// 
    /// ARCHITECTURE RAG :
    /// 1. RETRIEVAL : DÃ©lÃ©guÃ© Ã  RAGService (filtrage intelligent)
    /// 2. AUGMENTATION : Enrichissement du contexte (ce service)
    /// 3. GENERATION : Ollama gÃ©nÃ¨re la rÃ©ponse (ce service)
    /// 
    /// Ce service se concentre sur la partie GÃ‰NÃ‰RATION du RAG.
    /// </summary>
    public class OllamaRecommendationService : IRecommendationService
    {
        private readonly IHttpClientFactory _httpClientFactory;
        private readonly AppDbContext _context;
        private readonly IRAGService _ragService;
        private readonly string _ollamaUrl = "http://localhost:11434/api/generate";

        public OllamaRecommendationService(
            IHttpClientFactory httpClientFactory,
            AppDbContext context,
            IRAGService ragService)
        {
            _httpClientFactory = httpClientFactory;
            _context = context;
            _ragService = ragService;
        }

        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // ğŸ¤– MÃ‰THODE PRINCIPALE : RAG COMPLET (Retrieval + Augmentation + Generation)
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        public async Task<string> GetRecommendationsAsync(string userMessage)
        {
            try
            {
                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                // Ã‰TAPE 1 : RETRIEVAL (RÃ©cupÃ©ration depuis la base de donnÃ©es)
                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                var produits = await _context.Produits.ToListAsync();

                if (!produits.Any())
                {
                    return " Aucun produit disponible dans la base de donnees.";
                }

                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                // Ã‰TAPE 2 : FILTRAGE INTELLIGENT (DÃ©lÃ©guÃ© Ã  RAGService)
                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                var produitsRelevants = _ragService.RetrieveRelevantProducts(userMessage, produits);

                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                // Ã‰TAPE 3 : AUGMENTATION (Enrichissement du contexte)
                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                var produitsContext = BuildProductContext(produitsRelevants);
                var statsContext = $"[Produits trouvÃ©s: {produitsRelevants.Count}/{produits.Count}]";

                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                // Ã‰TAPE 4 : GENERATION (GÃ©nÃ©ration de rÃ©ponse avec Ollama)
                // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                var prompt = BuildPrompt(statsContext, produitsContext, userMessage);
                var response = await CallOllamaAsync(prompt);
                
                // Ajouter un indicateur RAG dans la rÃ©ponse
                return $"{response}\n\nğŸ’¡ RAG: {produitsRelevants.Count} produits analysÃ©s sur {produits.Count}";
            }
            catch (Exception ex)
            {
                return $" Erreur lors de la generation des recommandations : {ex.Message}\n\n" +
                   $" Verifiez que Ollama est demarre : `ollama serve`";
            }
        }

        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // ğŸ“ CONSTRUCTION DU PROMPT (Augmentation)
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        /// <summary>
        /// Construit le prompt enrichi pour le LLM.
        /// C'est la partie "Augmentation" du RAG.
        /// </summary>
        private string BuildPrompt(string stats, string productsContext, string userMessage)
        {
            return $@"Tu es un assistant e-commerce expert.

{stats}
Produits pertinents sÃ©lectionnÃ©s :
{productsContext}

Question client : {userMessage}

Instructions :
- RÃ©ponds en franÃ§ais prÃ©cis
- Utilise UNIQUEMENT les produits listÃ©s ci-dessus
- Format : â€¢ Nom (Prixâ‚¬)
- Si filtre de prix, vÃ©rifie bien le prix de chaque produit
- Maximum 5 lignes

RÃ©ponse :";
        }

        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // ğŸ“‹ FORMATAGE DU CONTEXTE PRODUITS
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        /// <summary>
        /// Construit le contexte des produits pour le prompt.
        /// Format compact pour rÃ©duire les tokens.
        /// </summary>
        private string BuildProductContext(List<Models.Produit> produits)
        {
            var sb = new StringBuilder();
            var produitsLimites = produits.Take(10).ToList();

            foreach (var p in produitsLimites)
            {
                sb.AppendLine($"- {p.Nom} | {p.Prix:F0}â‚¬ | {p.Categorie ?? "Autre"}");
            }
            return sb.ToString();
        }

        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // ğŸ¤– COMMUNICATION AVEC OLLAMA (LLM)
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        /// <summary>
        /// Appelle l'API Ollama pour gÃ©nÃ©rer une rÃ©ponse.
        /// Utilise gemma:2b avec tempÃ©rature basse pour plus de prÃ©cision.
        /// </summary>
        private async Task<string> CallOllamaAsync(string prompt)
        {
            // CrÃ©er le client HTTP via la factory
            var client = _httpClientFactory.CreateClient();
            client.Timeout = TimeSpan.FromMinutes(3);

            var requestBody = new
            {
                // âš¡ AVEC RAG : On peut utiliser gemma:2b car on envoie moins de produits
                model = "gemma:2b",        // âœ… OPTIMAL pour RAG : prÃ©cis et rapide
                
                prompt = prompt,
                stream = false,
                options = new
                {
                    temperature = 0.2,      // âš¡ Bas pour plus de prÃ©cision (RAG nÃ©cessite moins de crÃ©ativitÃ©)
                    num_predict = 150,      // Un peu plus long pour des rÃ©ponses complÃ¨tes
                    num_ctx = 512
                }
            };

            var jsonContent = JsonSerializer.Serialize(requestBody);

            // Creer le contenu HTTP avec le JSON
            var content = new StringContent(jsonContent, Encoding.UTF8, "application/json");

            try
            {
                var response = await client.PostAsync(_ollamaUrl, content);

                if (!response.IsSuccessStatusCode)
                {
                    var errorContent = await response.Content.ReadAsStringAsync();
                    return $" Erreur Ollama ({response.StatusCode}): {errorContent}";
                }

                var responseContent = await response.Content.ReadAsStringAsync();
                var jsonResponse = JsonDocument.Parse(responseContent);

                var recommendation = jsonResponse.RootElement
                    .GetProperty("response")
                    .GetString();

                return recommendation ?? "Aucune recommandation gÃ©nÃ©rÃ©e.";
            }
            catch (HttpRequestException ex)
            {
                return $" Impossible de se connecter Ã  Ollama.\n\n" +
                       $" VÃ©rifiez que Ollama est dÃ©marrÃ© :\n" +
                       $"   1. Ouvrez un terminal\n" +
                       $"   2. ExÃ©cutez : `ollama serve`\n\n" +
                       $"Erreur technique : {ex.Message}";
            }
        }
    }
}
